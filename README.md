ğŸ”¥ FORGE OS
Turning the entire internet into self-learning MCP servers.
Every webpage becomes a tool. Every tool evolves itself. Every workflow writes itself.

What is FORGE OS?
FORGE OS is an MCP App that renders a desktop-like operating system inside ChatGPT and Claude. Your MCP servers appear as apps in a dock. But this isn't a launcher â€” it's alive.

FORGE OS does three things that have never been built before:

ğŸŒ Endpointify â€” Turn any webpage into an MCP server
Paste any URL. FORGE OS analyzes the page with LLM vision + DOM heuristics, identifies every interactive component â€” search bars, buttons, forms, tables, filters â€” and turns each one into an MCP tool. No API needed. No developer needed.

There are 5,800 MCP servers today. There are 2 billion websites. FORGE OS bridges that gap.

Example: Your team's internal admin panel has no API and no MCP server. Paste the URL into FORGE OS. 30 seconds later, ChatGPT can search tickets, filter by status, and create new issues â€” on a page that has zero API endpoints.

ğŸ§¬ Self-Optimize â€” Every server gets measurably better
Every tool call flows through a structured telemetry layer. FORGE OS calls its companion optimization server â€” which runs real Optuna (TPE/CMA-ES) â€” to suggest better configurations: rewritten tool descriptions, tuned parameter defaults, improved retry strategies.

You see a split-test comparison card in the widget. Accept or reject. Your feedback is a reward signal that drives the next optimization trial. The tools you used yesterday are measurably faster and more accurate today.

This is not a mock. This is real Bayesian optimization running real trials.

âš¡ Auto-Generate â€” Tools nobody designed, born from how you work
FORGE OS watches your tool-call patterns. When it detects you always call Slack â†’ GitHub â†’ Calendar in sequence, it generates a composite tool (team-pulse) that collapses three calls into one â€” 4x faster, one click.

These composite tools appear as proposals in the widget. Test them. Accept them. A new app icon appears in your dock. Nobody designed it. It emerged from your workflow.


Architecture
Two MCP servers. One Manufact Cloud pool. Even the optimizer is an MCP server â€” it's MCP servers all the way down.

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Manufact MCP Cloud â”‚
â”‚ â”‚
â”‚ forge-os (TypeScript) forge-optimizer (Python)â”‚
â”‚ â”œâ”€â”€ endpointify() â”œâ”€â”€ suggest_trial() â”‚
â”‚ â”œâ”€â”€ endpointify_generate()â”œâ”€â”€ record_feedback() â”‚
â”‚ â”œâ”€â”€ route_query() â”œâ”€â”€ get_best_config() â”‚
â”‚ â”œâ”€â”€ optimize() â””â”€â”€ get_trial_history()â”‚
â”‚ â”œâ”€â”€ accept_optimization() â”‚
â”‚ â”œâ”€â”€ reject_optimization() Optuna (TPE/CMA-ES) â”‚
â”‚ â”œâ”€â”€ generate_composite() InMemoryStorage â”‚
â”‚ â”œâ”€â”€ test_composite() Real Bayesian opt. â”‚
â”‚ â”œâ”€â”€ get_status() â”‚
â”‚ â””â”€â”€ load_evolved_state() â”‚
â”‚ â”‚
â”‚ User's MCP servers: â”‚
â”‚ â”œâ”€â”€ slack, github, calendar (existing) â”‚
â”‚ â”œâ”€â”€ admin-panel (endpointified from URL) â”‚
â”‚ â””â”€â”€ team-pulse (auto-generated composite) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
ChatGPT / Claude
Widget renders inline

forge-os (TypeScript MCP App)
The main application. Exposes all user-facing tools. Renders the interactive widget UI per the MCP Apps standard. Built with mcp-use TypeScript SDK.

forge-optimizer (Python MCP Server)
Wraps Optuna as an MCP server with four tools. Real TPE and CMA-ES sampling. One study per server, created on demand, InMemoryStorage. Built with mcp-use Python SDK.

forge-os calls forge-optimizer via mcp-use â€” standard MCP tool calls within the same server pool. No HTTP sidecar. No custom protocols. Pure MCP.


The Widget
FORGE OS renders a full desktop workspace as an MCP App widget inside the chat client:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FORGE Bar â”‚
â”‚ ğŸ§¬ 12 optimizations âš¡ +340% speed ğŸ†• 2 new ğŸŒ 3 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚ Activity Feed â”‚
â”‚ Floating Panels â”‚ â”‚
â”‚ (results, comparisons, â”‚ ğŸŒ Endpointifiedâ”‚
â”‚ component maps) â”‚ admin-panel â”‚
â”‚ â”‚ â”‚
â”‚ â”‚ ğŸ”§ Optimized â”‚
â”‚ â”‚ slack.search â”‚
â”‚ â”‚ +45% accuracy â”‚
â”‚ â”‚ â”‚
â”‚ â”‚ ğŸ†• Composite â”‚
â”‚ â”‚ team-pulse â”‚
â”‚ â”‚ [Test][Reject] â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Dock â”‚
â”‚ [SlackğŸŸ¢] [GitHubğŸŸ¢] [CalğŸŸ¡] [AdminğŸŒğŸ”µ] [PulseğŸ”µ] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Health rings: ğŸŸ¢ optimized | ğŸŸ¡ analyzing | ğŸ”µ newly created | ğŸ”´ degraded


Widget â†” Model Interactions
FORGE OS uses four constant, bidirectional interaction loops between the widget and the model â€” the widget is never static:

Loop 1: Endpointify
User pastes URL â†’ model calls endpointify() â†’ widget renders Component Map with checkboxes for each detected element â†’ user selects components â†’ clicks "Endpointify" â†’ useCallTool() fires endpointify_generate() â†’ new app icon fades into dock with ğŸŒ badge â†’ sendFollowUpMessage() confirms the new app is ready.

Loop 2: Chat â†’ OS Routing
User types a question â†’ model calls route_query() â†’ widget shows animated paths between dock icons â†’ results populate in floating panels â†’ user clicks a different dock icon to override â†’ useCallTool() re-routes â†’ FORGE logs preference for future optimization.

Loop 3: Split-Test Optimization
FORGE calls optimizer for a suggested variant â†’ runs both original and candidate â†’ widget pops a comparison card (before/after metrics) â†’ user clicks Accept or Reject â†’ sendFollowUpMessage() sends reward to optimizer â†’ health ring updates â†’ Optuna samples smarter next time.

Loop 4: Composite Proposals
Telemetry detects repeated tool-call chain â†’ FORGE generates composite tool â†’ widget slides in proposal card â†’ user clicks "Test" â†’ useCallTool() executes composite â†’ results appear in panel â†’ user accepts â†’ new icon appears in dock.


Demo Walkthrough
Minute 1 â€” Endpointify: "Turn a webpage into an MCP server"
Launch FORGE OS â†’ desktop workspace appears with three app icons (Slack, GitHub, Calendar). Paste an internal admin panel URL â†’ Component Map shows detected elements (search bar, filter, create button, data table) â†’ select all â†’ click Endpointify â†’ new ğŸŒğŸ”µ icon appears in dock. Ask: "Show me all critical open tickets" â†’ it works. ChatGPT just queried a webpage with zero API.

Minute 2 â€” Self-Optimization: "Same tools, dramatically better"
Ask: "Catch me up on engineering" â†’ slow response, 3 tool calls, 12 seconds. FORGE has been analyzing. Same question again â†’ split-test card appears, optimized version is 3x faster with higher relevance. Accept. Health rings turn green. Activity feed shows a new composite tool was generated: team-pulse. Test it â†’ instant, perfect result. Accept â†’ new blue icon in dock.

Minute 3 â€” Evolution: "A week of learning in one click"
Load pre-evolved state. Dock now has 8 icons: 3 original + 2 endpointified + 3 auto-generated composites. All green health rings. FORGE Bar: 47 optimizations | +340% speed | 3 new apps | 2 endpointified. Complex query spanning all apps â†’ 2 seconds, comprehensive answer. The same query took 12 seconds three days ago.


The Technology Behind the Optimization
The optimization engine inside FORGE OS is built on the same technology as Aviran, our agent optimization platform (8 active customers).

How it works:

Every MCP server configuration is decomposed into parameter paths: tool descriptions, parameter defaults, retry strategies, routing preferences, timeout thresholds
Every user interaction (accept/reject/override) generates a reward signal
Optuna samples the next configuration to try using TPE (Tree-structured Parzen Estimator) for discrete choices and CMA-ES for continuous parameters
Each trial is stored with its parameter path and reward score
The optimizer converges on the best configuration for each server, for each user's specific usage patterns
This is not prompt engineering. This is real Bayesian hyperparameter optimization applied to MCP server configurations.


Endpointify: How It Works
The endpointify pipeline uses a layered extraction strategy for maximum reliability:

Playwright fetches the page with a deterministic viewport and wait strategy
LLM Vision (primary pass) analyzes a screenshot + DOM summary to semantically identify interactive components â€” understanding what each element does, not just what it looks like
Heuristic fallback parses DOM/ARIA for standard patterns (input[type=search], <form>, <table>, <button>) when the vision model is slow or low-confidence
Merge + deduplicate results by selector signature with confidence ranking
Generate MCP tools from selected components â€” each component maps to a tool with a name, description, and input schema
The result: any webpage becomes a set of MCP tools without writing a single line of code.


Built With
Technology
Role
mcp-use TypeScript SDK
forge-os server + React widget
mcp-use Python SDK
forge-optimizer server
Manufact MCP Cloud
Deployment (both servers in one pool)
Manufact Inspector
Testing and debugging
Optuna
Real TPE/CMA-ES Bayesian optimization
Playwright
Page fetching for endpointify
MCP Apps standard
Widget rendering in ChatGPT/Claude
React
Widget UI components

Sponsor Integration
Sponsor
How FORGE OS Uses It
Manufact
SDK, Inspector, Cloud â€” the entire build-test-deploy pipeline. FORGE OS creates and deploys MCP servers on their cloud.
Anthropic
Claude as LLM backbone for routing, endpointify vision analysis, and optimization evaluation.
OpenAI
ChatGPT as primary demo client. Widget renders inline via MCP Apps / Apps SDK.
Cloudflare
Workers available for sandboxed page interaction in endpointify pipeline.
WorkOS
AuthKit integration path for production multi-tenant access (post-hackathon).
Puzzle
Cost analytics dimension â€” optimization tracks token spend per tool alongside quality and speed.

What's Next
FORGE OS is a preview of what we're building at Aviran â€” self-learning infrastructure for AI agents. Our optimization engine uses Optuna with TPE and CMA-ES to evolve agent configurations based on real usage data. We have 8 active customers today.

The endpointify engine opens up the entire internet as MCP tool surface area. The optimization engine makes every tool better over time. Combined, they point toward a future where AI tools aren't configured by humans â€” they evolve.


Team
Built at the MCP Apps Hackathon by Manufact, Feb 21, 2026, at Y Combinator SF.


FORGE OS â€” Turning the entire internet into self-learning MCP servers.
